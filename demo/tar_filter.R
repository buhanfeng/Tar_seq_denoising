
# install denoising function
source('./tar_region_denoising.R')
# set working directory
print(getwd())
setwd('./')

# initializing, tar_gtf is the gtf generated by tar-seq.
# note that gtf file might have annotation at the beginning, which should be 
#   deleted before calling this function.
tar_obj = initializing('./tar.gtf')

# summary the number of region categorized by type
# summary the length and expression quartile
regions_summary(tar_obj)

# ------------------ remove by overlap -------------------
# discarding tar regions which overlap with putative gene.
tar_obj = discard_overlap_regions(tar_obj)

# ------------------ remove by length --------------------
# check distribution of length
tar.dot_plot(tar_obj, by='length')
# remove abnormal outliers base on plot result
tar_obj = tar.cut(tar_obj, by='length', head = 50000)
tar.dot_plot(tar_obj, by='length')
# remove abnormal short tar regions
tar_obj = tar.cut(tar_obj, by='length', tail = 60)
# remove suspicious long region by accumulation
tar_obj = 
  tar.cut(tar_obj, by='length', head = accumulateX(tar_obj, by='length', X=5))
tar.dot_plot(tar_obj, by='length')

# ------------------ remove by expression --------------------
# check distribution of expression
tar.dot_plot(tar_obj, by='expression')
# remove abnormal outliers base on plot result
tar_obj = tar.cut(tar_obj, by='expression', head = 40000)
tar.dot_plot(tar_obj, by='expression')
# check distribution of normalized expression
tar.dot_plot(tar_obj, by='expression_nor')
# remove suspicious large expression by accumulation
tar_obj = tar.cut(tar_obj, by='expression_nor', 
                  head = accumulateX(tar_obj, by='expression_nor', X=5))

# ------------------ to here, the extreme value(both length and expression) were all
# removed, but still here will remain lots of regions. to go a step further, we
# can filter low expression value base on 'elbow and accumulation' or 'sparsity'.
# ------------------

# ------------------ elbow and accumulation ------------------
# find elbow in expression_nor
eb = find_elbow(tar_obj, by='expression_nor')
tar.dot_plot(tar_obj, by='expression_nor', highlight = eb)
# cut low expression region base on accumulation start from elbow
ac80 = accumulateX(tar_obj, by='expression_nor', X=80, start_from=eb[2])
tar.dot_plot(tar_obj, by='expression_nor', highlight = ac80)
tar_obj = tar.cut(tar_obj, by='expression_nor', tail = ac80[2])

# alternatively, we can include the area from 0 to elbow and set the accumulation
# cut off to 95
ac95 = accumulateX(tar_obj, by='expression_nor', X=95)
tar.dot_plot(tar_obj, by='expression_nor', highlight = ac95)
tar_obj = tar.cut(tar_obj, by='expression_nor', tail = ac95[2])


# ------------------ sparsity ---------------------
# sparsity method investigate tar region's expression from each cell, and 
# turn expression into binary (0 for zero and 1 for non zero). then sum up non
# zero value to estimate how much a region contribute to the sparsity. consequently,
# sparsity need to pre-run cellranger to get the expression matrix.
# 1. export gtf
tar_obj = generate_tar_denoised_gtf(tar_obj, file='pre_tar_denoised.gtf')
# 2. cellranger mkref, mk reference genome by pre_tar_denoised.gtf
# 3. cellranger count
# 4. read expression matrix
tar_obj = tar.read_10x(tar_obj, path = './filtered_feature_bc_matrix')
# 5. parse sparsity
tar_obj = parse_sparsity(tar_obj)
# 6. check sparsity curve
tar.dot_plot(tar_obj, by='sparsity')
# 7. find elbow of sparsity curve
# filter high sparsity region according to minimum cell number of cluster and 
# elbow, by default, minimum cell number of cluster is 10, and let say the elbow
# is 6, we set the threshold to (10+6)/2
eb = find_elbow(tar_obj, by='sparsity')
tar.dot_plot(tar_obj, by='sparsity', highlight = eb)
tar_obj = tar.cut(tar_obj, by='sparsity', tail = (eb[1]+10)/2)

# ------------------ to blast ---------------------
regions_summary(tar_obj)
to_blast(tar_obj)

# ------------------ run follow cmd on linux ------------
# samtools faidx -r toblast.txt genome.fa > toblast.fa
# blastn -db /nt -query toblast.fa -out blast.tsv -outfmt '6 qseqid sseqid stitle pident length mismatch gapopen qstart qend sstart send evalue bitscore' -max_target_seqs 5 -num_threads 20
# empirically, blast requires 1 hour per 10000 records under 20 cores.(more cores doesn't make it better.)

# ------------------ filtering by blast result -----------------
tar_obj = read_blast(tar_obj)
tar_obj = check_blast(tar_obj)
tar_obj = filter_by_blast(tar_obj)
tar_obj = generate_tar_denoised_gtf(tar_obj)
generate_merge_gtf(tar_obj)


# ----- check mapping performace by comparing merge gtf and putative gtf ------
# cellranger mkref \
# --nthreads 30 \
# --genome=x1_combined_tar \
# --fasta=/RAID_32T/fbh/Agl/TubewormParaescarpiaEchinospica/ref_genome/combined.fa \
# --genes=/RAID_32T/fbh/Agl/TubewormParaescarpiaEchinospica/ref_genome/combined_tar.gtf

# cellranger count --id=x1_combined_tar \
# --fastqs=/RAID_32T/fbh/Agl/TubewormParaescarpiaEchinospica/fastq/tub1 \
# --sample=tub1 \
# --transcriptome=/RAID_32T/fbh/Agl/TubewormParaescarpiaEchinospica/ref_genome/x1_combined_tar












